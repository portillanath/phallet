{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Set paths\n",
    "source = os.path.expanduser(\"~/phallet/Blast_Feed\")\n",
    "subdirectories = [d for d in os.listdir(source)]\n",
    "workdir = os.path.expanduser(\"~/phallet/Metrics_Results\")\n",
    "\n",
    "# Create output directories\n",
    "for genus in subdirectories:\n",
    "    genus_name = os.path.basename(os.path.normpath(genus))\n",
    "    genus_dir = os.path.join(workdir, genus_name)\n",
    "     # Check if the directory already exists\n",
    "    if not os.path.exists(genus_dir):\n",
    "        os.makedirs(genus_dir)\n",
    "    #Move all the files to the corresponding directory\n",
    "    if os.path.exists(genus_dir):\n",
    "        files_to_move = [f for f in os.listdir(workdir) if os.path.isfile(os.path.join(workdir, f)) and genus_name in f]\n",
    "        dirs_to_move= [d for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d)) and f\"signatures_{genus_name}\" in d]\n",
    "        for file in files_to_move:\n",
    "           os.rename(file, os.path.join(genus_dir,file))\n",
    "        for dir in dirs_to_move:\n",
    "            os.rename(dir, os.path.join(genus_dir,dir))\n",
    "\n",
    "#Read command-line arguments\n",
    "args = sys.argv[1:]\n",
    "mx = \"ani\"\n",
    "kmersx = [12, 11, 10, 9, 8]\n",
    "my = \"mash\"\n",
    "kmersy = [15, 17, 20, 21, 24]\n",
    "\n",
    "# Remove any arguments that are not valid integers\n",
    "args = [arg for arg in args if re.match(r'^\\d+$', arg)]\n",
    "\n",
    "# Parse the remaining arguments\n",
    "if len(args) > 0:\n",
    "    mx = args[0]\n",
    "if len(args) > 1:\n",
    "    kmersx = list(map(int, args[1].split(\",\")))\n",
    "if len(args) > 2:\n",
    "    my = args[2]\n",
    "if len(args) > 3:\n",
    "    kmersy = list(map(int, args[3].split(\",\")))\n",
    "\n",
    "# Set up directories on workdir\n",
    "subdirectories = [d for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d))]\n",
    "\n",
    "# SEARCH FOR OUTPUT FILES\n",
    "# Recover possible algorithms for each metric of the pairwise correlation\n",
    "# Cases for metrics selected available\n",
    "if mx == \"mash\":\n",
    "    tool_mx = [\"mash\", \"sourmash\"]\n",
    "elif mx == \"ani\":\n",
    "    tool_mx = [\"fastani\", \"skani\"]\n",
    "elif mx == \"aai\":\n",
    "    tool_mx = [\"comparem\"]\n",
    "elif mx == \"viridic\":\n",
    "    tool_mx = [\"viridic\"]\n",
    "elif mx == \"vcontact2\":\n",
    "    tool_mx = [\"vcontact2\"]\n",
    "else:\n",
    "    raise ValueError(\"Invalid metric selected\")\n",
    "\n",
    "# Cases for metrics selected on Y\n",
    "if my == \"mash\":\n",
    "    tool_my = [\"mash\", \"sourmash\"]\n",
    "elif my == \"ani\":\n",
    "    tool_my = [\"fastani\", \"skani\"]\n",
    "elif my == \"aai\":\n",
    "    tool_my = [\"comparem\"]\n",
    "elif my == \"viridic\":\n",
    "    tool_my = [\"viridic\"]\n",
    "elif my == \"vcontact2\":\n",
    "    tool_my = [\"vcontact2\"]\n",
    "else:\n",
    "    raise ValueError(\"Invalid metric selected\")\n",
    "\n",
    "metrics = [mx, my]\n",
    "\n",
    "# This makes the parsing for the corresponding metric\n",
    "fastani_results = pd.DataFrame()\n",
    "skani_results = pd.DataFrame()\n",
    "mash_results =pd.DataFrame()\n",
    "sourmash_results=pd.DataFrame()\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    os.chdir(workdir)\n",
    "    if not os.path.exists(subdir):\n",
    "        continue\n",
    "    subdir_name = os.path.basename(subdir)\n",
    "    genomes=[]\n",
    "    for m in metrics:\n",
    "        if m == mx:\n",
    "            tool_list = tool_mx\n",
    "            kmers = kmersx\n",
    "        if m == my:\n",
    "            tool_list = tool_my\n",
    "            kmers = kmersy\n",
    "\n",
    "        for tool in tool_list:\n",
    "\n",
    "            # In case of having fastani metrics\n",
    "            if tool == \"fastani\":\n",
    "                files_fastani = glob(os.path.join(workdir, subdir_name, \"fastani*\"))\n",
    "                files_fastani = [file for file in files_fastani if not file.endswith('.csv')]\n",
    "                for file in files_fastani:\n",
    "                    k = int(file.split(\"_\")[-1].split(\".\")[0])\n",
    "                    data_fastani = pd.read_csv(file, header=None, sep='\\t')\n",
    "                    data_fastani = data_fastani.iloc[:, :3]\n",
    "                    data_fastani['kmer_ani'] = k\n",
    "                    data_fastani['algorithm'] =\"fastani\"\n",
    "                    data_fastani.columns = [\"GenomeA\", \"GenomeB\", \"ani_distance\", \"kmer_ani\",\"algorithm\"]\n",
    "                    data_fastani['GenomeA'] = data_fastani['GenomeA'].replace('.*/', '', regex=True)\n",
    "                    data_fastani['GenomeB'] = data_fastani['GenomeB'].replace('.*/', '', regex=True)\n",
    "                    data_fastani['GenomeA'] = data_fastani['GenomeA'].replace('.fasta', '', regex=True)\n",
    "                    data_fastani['GenomeB'] = data_fastani['GenomeB'].replace('.fasta', '', regex=True)\n",
    "                    fastani_results = pd.concat([fastani_results, data_fastani])\n",
    "                \n",
    "            fastani_results.to_csv(os.path.join(workdir, subdir_name, f\"fastani_results_{subdir_name}.csv\"), index=False)\n",
    "            \n",
    "            # In case of having skani metrics\n",
    "            if tool==\"skani\":\n",
    "             files_skani = glob(os.path.join(workdir, subdir_name, \"skani*\"))\n",
    "             files_skani = [file for file in files_skani if not file.endswith('.csv')]\n",
    "             for file in files_skani:  \n",
    "                data_skani = pd.read_csv(file, header=None, sep='\\t', names=[\"Ref_file\",\"Query_file\",\"ANI\",\"Align_fraction_ref\",\"Align_fraction_query\",\"Ref_name\",\"Query_name\"])\n",
    "                data_skani = data_skani.iloc[:, :3]\n",
    "                data_skani['kmer_ani'] = \"static\"\n",
    "                data_skani['algorithm'] =\"skani\"\n",
    "                data_skani=data_skani.drop(index=0)\n",
    "                data_skani.columns = [\"GenomeA\", \"GenomeB\", \"ani_distance\", \"kmer_ani\",\"algorithm\"]\n",
    "                data_skani['GenomeA'] = data_skani['GenomeA'].replace('.*/', '', regex=True)\n",
    "                data_skani['GenomeB'] = data_skani['GenomeB'].replace('.*/', '', regex=True)\n",
    "                data_skani['GenomeA'] = data_skani['GenomeA'].replace('.fasta', '', regex=True)\n",
    "                data_skani['GenomeB'] = data_skani['GenomeB'].replace('.fasta', '', regex=True)\n",
    "                skani_results = pd.concat([skani_results, data_skani])\n",
    "            \n",
    "            skani_results.to_csv(os.path.join(workdir, subdir_name, f\"skani_results_{subdir_name}.csv\"), index=False)   \n",
    "            \n",
    "            # In case of having mash metrics\n",
    "            if tool==\"mash\":\n",
    "             files_mash = glob(os.path.join(workdir, subdir_name, \"mash*.tab\"))\n",
    "             for file in files_mash:\n",
    "                k = int(re.search(r'k(\\d+)', file).group(1))\n",
    "                if k in kmers:\n",
    "                    data_mash = pd.read_csv(file, header=None, names=[\"GenomeA\", \"GenomeB\", \"mash_distance\", \"p-value\", \"shared_hashes\"], sep='\\t')\n",
    "                    data_mash = data_mash.iloc[:, :3]\n",
    "                    data_mash['kmer_mash'] = k\n",
    "                    data_mash['algorithm'] = \"mash\"\n",
    "                    data_mash['GenomeA'] = data_mash['GenomeA'].replace('.*/', '', regex=True)\n",
    "                    data_mash['GenomeB'] = data_mash['GenomeB'].replace('.*/', '', regex=True)\n",
    "                    data_mash['GenomeA'] = data_mash['GenomeA'].replace('.fasta', '', regex=True)\n",
    "                    data_mash['GenomeB'] = data_mash['GenomeB'].replace('.fasta', '', regex=True)\n",
    "                    mash_results = pd.concat([mash_results, data_mash])\n",
    "            mash_results.to_csv(os.path.join(workdir, subdir_name, f\"mash_results_{subdir_name}.csv\"), index=False)   \n",
    "\n",
    "            # In case of having sourmash metrics\n",
    "            if tool==\"sourmash\":\n",
    "              files_sourmash = glob(os.path.join(workdir, subdir_name, \"sourmash*.csv\"))\n",
    "              accessions_path=os.path.join(source,subdir_name)\n",
    "              accessions= os.listdir(accessions_path)\n",
    "              genomes= [os.path.splitext(file)[0] for file in accessions if file.endswith(\".fasta\")]\n",
    "              for file in files_sourmash:\n",
    "                k_values = [int(match.group(1)) for match in re.finditer(r'k(\\d+)', file)]\n",
    "                k = k_values[0] if k_values else None \n",
    "                #k = int(re.search(r\"k(\\d+)\", file).group(1))\n",
    "                if k in kmers:\n",
    "                    data_sourmash = pd.read_csv(file, sep=',')\n",
    "                    data_sourmash.columns = genomes\n",
    "                    data_sourmash.index = genomes\n",
    "                    data_sourmash=data_sourmash.to_numpy()\n",
    "                    distances=pdist(data_sourmash)\n",
    "                    square_distances=squareform(distances)\n",
    "                    i,j=np.triu_indices(square_distances.shape[0],k=1)\n",
    "                    data_sourmash = pd.DataFrame({\"GenomeA\": [genomes[int(idx)] for idx in i], \"GenomeB\": [genomes[int(idx)] for idx in j], \"mash_distance\": square_distances[i.astype(int), j.astype(int)]})\n",
    "                    data_sourmash['kmer_mash'] = k\n",
    "                    data_sourmash['algorithm']= \"sourmash\"\n",
    "                    sourmash_results = pd.concat([sourmash_results, data_sourmash], ignore_index=True)\n",
    "\n",
    "            mash_results.to_csv(os.path.join(workdir, subdir_name, f\"sourmash_results_{subdir_name}.csv\"), index=False)   \n",
    "\n",
    "#Merge of differents compend\n",
    "    ani_metrics_result=pd.concat([fastani_results,skani_results])\n",
    "    ani_metrics_result.to_csv(os.path.join(workdir,subdir_name,f\"ani_metrics_{subdir_name}.csv\"), index=False)\n",
    "    mash_metrics_result=pd.concat([mash_results,sourmash_results])\n",
    "    mash_metrics_result.to_csv(os.path.join(workdir,subdir_name,f\"mash_metrics_{subdir_name}.csv\"), index=False)\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
